{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "<!--\n",
    "\n",
    "### Requirements:\n",
    "\n",
    "You need to .....\n",
    "\n",
    "1. simualtion track\n",
    "2. hardware track\n",
    "    - DB21M up and running\n",
    "    - 2 AprilTags\n",
    "\n",
    "### Intended outcomes:\n",
    "\n",
    "Calibrate the Duckiebot kinematic model using the data from the wheel encoders.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. Theory  \n",
    "2. Approach\n",
    "3. Implementation\n",
    "4. Validation\n",
    "\n",
    "\n",
    "\n",
    "1. Theory -> Review odometry class\n",
    "2. Approach -> \n",
    "    - Use wheel encoders to estimate the pose of the DB using deadrecknonig approximation. \n",
    "    - Use estimate and ground truth to best fit\n",
    "\n",
    "3. Implementation ->\n",
    "    - Read the data from the wheel encoders \n",
    "        - Sim:\n",
    "        - HW :\n",
    "            \n",
    "    - Obtain the gorund truth from AprilTags\n",
    "\n",
    "\n",
    "4. Validation\n",
    "\n",
    "1. Theoretical understanding of the Duckiebot kinematic model, in particular what the parameters _R_ and _L_ represent.\n",
    "2. Approach:\n",
    "    - Wheel encoders and deadrecknonig\n",
    "    \n",
    "    - Straight path \n",
    "    - Curved path (e.g., sinusoidal)\n",
    "\n",
    "3. Validation of the resulting parameters.\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: right\">\n",
    "  <img src=\"../images/dtlogo.png\" alt=\"Logo\" width=\"200\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš™ ðŸ’» 05 - Wheel encoder based odometry\n",
    "\n",
    "\"Odometry\" is the problem of \"measuring the path\", or evolution of the pose in time, of the robot. \n",
    "\n",
    "We can solve the odometry problem by using the measurements from wheel encoders. We use the dead-reckoning model to estimate the evolution of the pose in time through an iterative procedure, such that:\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"../images/odometry/odometry-1.png\" width=\"500\" alt=\"odometry\"></p>   \n",
    "\n",
    "$$ x_{k+1} = x_k + \\Delta x_k $$\n",
    "$$ y_{k+1} = y_k + \\Delta y_k $$\n",
    "$$ \\theta_{k+1} = \\theta_k + \\Delta \\theta_k $$\n",
    "\n",
    "Where initial conditions ($x_0$, $y_0$, $\\theta_0$) are assumed to be known. The increments can be calculated by:\n",
    "\n",
    "1. Determining the rotation of each wheel through the wheel encoder mesurements\n",
    "\n",
    "$$\\Delta \\phi_k = N_k \\cdot \\alpha$$\n",
    "\n",
    "where $N_k$ is the number of pulses, or \"ticks\", measured from the encoders in the $k-th$ time interval, $\\alpha = \\frac{2 \\pi}{N_{tot}}$ is the rotation per tick, and $N_{tot}$ the total number of ticks per revolution ($N_{tot} = 135$ for the wheel encoders we will be using). This relation is evaluated for each wheel, yielding $\\Delta \\phi_{l,k}$ and $\\Delta \\phi_{r,k}$ for the left and right wheels respectively.\n",
    "\n",
    "2. Deriving the total distance travelled by each wheel\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"../images/odometry/odometry-d.png\" width=\"300\" alt=\"odometry\"></p> \n",
    "\n",
    "Assuming the wheel radii are the same (equal to $R$) for both wheels, the distance travelled by each wheel is given by:\n",
    "\n",
    "$$ d_{l/r, k} = R \\cdot \\Delta \\phi_{l/r,k}$$\n",
    "\n",
    "3. Find the rotation and distance travelled by the robot (frame)\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"../images/odometry/odometry-2.png\" width=\"300\" alt=\"odometry\"></p>    \n",
    "\n",
    "Under the assumption of no slipping of the robot wheel, we can derive the distance travelled by the origin of the robot frame (point $A$) and the rotation of the robot $\\Delta \\theta$:\n",
    "\n",
    "$$ d_{A, k} = \\frac{d_{r,k} + d_{l,k}}{2} $$\n",
    "$$ \\Delta \\theta_{k} = \\frac{d_{r,k} - d_{l,k}}{2L}$$\n",
    "\n",
    "4. Express the robot motion in the world reference frame\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"../images/odometry/odometry-3.png\" width=\"300\" alt=\"odometry\"></p>\n",
    "\n",
    "Finally, we can express the estimated motion in the world reference frame and find:\n",
    "\n",
    "$$ \\Delta x_k = d_{A, k} \\cos\\theta_k $$\n",
    "$$ \\Delta y_k = d_{A, k} \\sin\\theta_k $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get started!\n",
    "\n",
    "In this activity you will write a function that produces an estimate of the pose of the Duckiebot, given mesurements from the wheel encoders and an initial position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = y0 = 0 # meters\n",
    "theta0 = 0 # radians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Determining the rotation of each wheel through the wheel encoder mesurements\n",
    "\n",
    "We've seen how to read wheel encoder data. Let's now use it to measure how much each wheel has rotated. \n",
    "\n",
    "### Wheel encoder calibration factor\n",
    "\n",
    "Remember that there are 135 ticks per revolution on the wheel encoders we are using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The angular resolution of our encoders is: 2.6666666666666665 degrees\n"
     ]
    }
   ],
   "source": [
    "import numpy as np #TODO remove solution before publishing\n",
    " \n",
    "N_tot = 135 # total number of ticks per revolution\n",
    "alpha = 2 * np.pi / N_tot # wheel rotation per tick in radians\n",
    "\n",
    "print(f\"The angular resolution of our encoders is: {np.rad2deg(alpha)} degrees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution: The angular resolution of our encoders is: 2.6666666666666665 degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose that at the current update the encoders have produced the following measurements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks_left = 2\n",
    "prev_tick_left = 0\n",
    "\n",
    "ticks_right = 7\n",
    "prev_tick_right = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much did each wheel rotate? (Express your answer in degrees - machines always use radians, humans make sense of degrees better. Mixing these up is a very very common source of error!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The left wheel rotated: 5.333333333333333 degrees\n",
      "The right wheel rotated: 8.0 degrees\n"
     ]
    }
   ],
   "source": [
    "# write function to get delta ticks\n",
    "\n",
    "delta_ticks_left = ticks_left-prev_tick_left # delta ticks of left wheel in arbitrary dt\n",
    "delta_ticks_right = ticks_right-prev_tick_right # delta ticks of right wheel in same dt\n",
    "\n",
    "rotation_wheel_left = alpha * delta_ticks_left # total rotation of left wheel in dt\n",
    "rotation_wheel_right = alpha * delta_ticks_right # total rotation of right wheel in dt\n",
    "\n",
    "print(f\"The left wheel rotated: {np.rad2deg(rotation_wheel_left)} degrees\")\n",
    "print(f\"The right wheel rotated: {np.rad2deg(rotation_wheel_right)} degrees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution: \n",
    "\n",
    "The left wheel rotated: 5.333333333333333 degrees\n",
    "\n",
    "The right wheel rotated: 8.0 degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluate distance travelled by each wheel\n",
    "\n",
    "Now let's calculate the distance travelled by each wheel. It depends on the wheel radii. We need to determine it! We could use advanced odometry calibration procedures, but let's take it a step at the time. \n",
    "\n",
    "Take a ruler and measure you wheel radii (let's assume they are the same):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 0.033 # insert value measured by ruler, in *meters*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the default value used in simulation and on the robot is $R = 0.0318 \\text{m}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The left wheel travelled: 0.00307177948351002 meters\n",
      "The right wheel rotated: 0.004607669225265031 meters\n"
     ]
    }
   ],
   "source": [
    "# What is the distance travelled by each wheel?\n",
    "\n",
    "d_left = R * rotation_wheel_left \n",
    "d_right = R * rotation_wheel_right\n",
    "\n",
    "print(f\"The left wheel travelled: {d_left} meters\")\n",
    "print(f\"The right wheel rotated: {d_right} meters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸš™ Save your new value of `R`\n",
    "\n",
    "If you have a Duckiebot, let's make sure it remembers its new wheel radius! You should already know how to do this from [wheel calibration tutorial](../03-Wheel-Calibration/wheels_calibration.ipynb). \n",
    "\n",
    "Else, you can follow this slightly more straightforward approach. Power you Duckiebot on, make sure it is connected to the network and you can ping it, then open a terminal **on your computer** and type:\n",
    "\n",
    "    dts start_gui_tools ROBOTNAME\n",
    "    \n",
    "    rosparam set /ROBOTNAME/kinematics_node/radius R-value\n",
    "    \n",
    "where `R-value` is the value of the wheel radius you measured (expressed in meters). You can then save it with: \n",
    "\n",
    "    rosservice call /ROBOTNAME/kinematics_node/save_calibration\n",
    "    \n",
    "and finally verify that it has been saved by opening the `ROBOTNAME.yaml` file in your Dashboard > File Manager > Calibrations > Kinematics page.\n",
    "\n",
    "You can keep the terminal you just used open, so we can save the baseline measurement too. Let's keep going!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find the rotation and distance travelled by the robot (frame)\n",
    "\n",
    "If you have previoulsy set your robot's gain so that the wheels do not slip, the travelled distance of point $A$ (origin of the robot frame) will be given by the average of the distances travelled by the wheels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The robot has travelled: 0.0038397243543875255 meters\n"
     ]
    }
   ],
   "source": [
    "# How much has the robot travelled? \n",
    "\n",
    "d_A = (d_left + d_right)/2\n",
    "\n",
    "print(f\"The robot has travelled: {d_A} meters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the rotation of the robot we need to measure the baseline - or the distance from the ceter of the two wheels. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "To do so we need to measure the baseline that is the distance between the center of the two wheels.\n",
    "Take a ruler and mesure it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_wheel2wheel = 0.108 #  Distance between the center of the two wheels, expressed in meters (e.g., 10.8cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JT TODO: add instructions on how to go to VNC and set and save the new L** (or directly through start_gui_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delta_Theta = (d_right-d_left)/baseline_wheel2wheel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "### Step 10\n",
    "\n",
    "Write in the cell below the code to estimate the pose of the Duckiebot using data given by the wheel encoders.\n",
    "\n",
    "**DO NOT CHANGE THE NAME OF THE FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "def DeltaPhi(encoder_msg, prev_ticks):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            encoder_msg (ROS encoder message)\n",
    "            prev_ticks (Current ticks)\n",
    "        Return:\n",
    "            rotation_wheel (double) Rotation of the wheel\n",
    "            ticks (int) current number of ticks\n",
    "    \"\"\"\n",
    "    ticks = encoder_msg.data\n",
    "\n",
    "    delta_ticks = ticks-prev_ticks\n",
    "\n",
    "    N_tot = encoder_msg.resolution\n",
    "\n",
    "    alpha = 2*np.pi/N_tot\n",
    "\n",
    "    rotation_wheel = alpha*delta_ticks\n",
    "    \n",
    "    return rotation_wheel, ticks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "# The function written in this cell will actually be ran on your robot (sim or real). \n",
    "# Put together the steps above and write your odometry function! \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "# DO NOT CHANGE THE NAME OF THIS FUNCTION OR THINGS WILL BREAK\n",
    "\n",
    "def poseEstimation( R, # radius of wheel (assumed identical)\n",
    "                    baseline_wheel2wheel, # distance from wheel to wheel (center); 2L of the theory\n",
    "                    x_prev, # previous estimate - assume given\n",
    "                    y_prev, # previous estimate - assume given\n",
    "                    theta_prev, # previous estimate - assume given\n",
    "                    delta_phi_left, # previous estimate - assume given\n",
    "                    delta_phi_right):\n",
    "    \"\"\"\n",
    "        Calculate the current Duckiebot pose using dead reckoning approach.\n",
    "\n",
    "        Returns x,y,theta current estimates:\n",
    "            x_curr, y_curr, theta_curr (:double: values)\n",
    "    \"\"\"\n",
    "    x_curr = x_prev + R*(delta_phi_left+delta_phi_right)*np.cos(theta_prev)/2\n",
    "    y_curr = y_prev + R*(delta_phi_left+delta_phi_right)*np.sin(theta_prev)/2\n",
    "    theta_curr = theta_prev + R*(delta_phi_right-delta_phi_left)/baseline_wheel2wheel\n",
    "    \n",
    "    return x_curr, y_curr, theta_curr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the poseEstimation function\n",
    "\n",
    "Unit tests are useful to check if the piece of code you write does its intended job.\n",
    "If the tests are good you will not see any output.\n",
    "\n",
    "Let's see if the function you wrote above passes the following test!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'unit_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-33bdb73b7a48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0munit_test\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUnitTestOdometry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.033\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbaseline_wheel2wheel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.108\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'unit_test'"
     ]
    }
   ],
   "source": [
    "from unit_test import UnitTestOdometry\n",
    "\n",
    "R = 0.033\n",
    "baseline_wheel2wheel = 0.108\n",
    "\n",
    "UnitTestOdometry(R, baseline_wheel2wheel, poseEstimation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "### Run the Activity\n",
    "\n",
    "** TODO: Jacopo write the testing experience both in simulation and on the real robot**\n",
    "\n",
    "Objective is drive robot around and see the odometry track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "! cd .. && dts exercises build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "### Run the Activity in simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "! cd .. && dts exercises test --sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "After running the above command, open the following link http://localhost:8087 you will visualize the VNC. Then from the VNC open RVIZ, press the `Add` on the bottom left side of the window, after that go to the tab `topics` and select `/DUCKIEBOT_NAME/encoder_localization`. Finally open the joystick (on the Desktop) and move the robot. You will see that the pose arrow start moving according to the given commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "### Run the activity on the Duckiebot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "! cd .. && dts exercises test --duckiebot_name ![DB_NAME] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "After running the above command, open the following link http://localhost:8087 you will visualize the VNC. Then from the VNC open RVIZ, press the `Add` on the bottom left side of the window, after that go to the tab `topics` and select `/DUCKIEBOT_NAME/encoder_localization`. Finally open the joystick (on the Desktop) and move the robot. You will see that the pose arrow start moving according to the given commands."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
