{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "### Requirements:\n",
    "\n",
    "You need to .....\n",
    "\n",
    "1. simualtion track\n",
    "2. hardware track\n",
    "    - DB21M up and running\n",
    "    - 2 AprilTags\n",
    "\n",
    "### Intended outcomes:\n",
    "\n",
    "Calibrate the Duckiebot kinematic model using the data from the wheel encoders.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. Theory  \n",
    "2. Approach\n",
    "3. Implementation\n",
    "4. Validation\n",
    "\n",
    "\n",
    "\n",
    "1. Theory -> Review odometry class\n",
    "2. Approach -> \n",
    "    - Use wheel encoders to estimate the pose of the DB using deadrecknonig approximation. \n",
    "    - Use estimate and ground truth to best fit\n",
    "\n",
    "3. Implementation ->\n",
    "    - Read the data from the wheel encoders \n",
    "        - Sim:\n",
    "        - HW :\n",
    "            \n",
    "    - Obtain the gorund truth from AprilTags\n",
    "\n",
    "\n",
    "4. Validation\n",
    "\n",
    "1. Theoretical understanding of the Duckiebot kinematic model, in particular what the parameters _R_ and _L_ represent.\n",
    "2. Approach:\n",
    "    - Wheel encoders and deadrecknonig\n",
    "    \n",
    "    - Straight path \n",
    "    - Curved path (e.g., sinusoidal)\n",
    "\n",
    "3. Validation of the resulting parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš™ ðŸ’» Step 1: obtain wheel encoder measurements. \n",
    "\n",
    "The first step to evaluate to Duckiebot's odometry is to measure the data from the wheel encoders. Let's get some of these messages and understand what they mean.\n",
    "\n",
    "## ðŸ’» Read data from wheel encoders\n",
    "\n",
    "- Open a terminal on your computer \n",
    "- `dts exercises build` \n",
    "-  `dts exercises test --sim`\n",
    "    - find localhost address novnc and paste in browser\n",
    "    - open RQT image view, select compressed image topic from the dropdown menu\n",
    "    - open LX terminal inside novnc\n",
    "    - rostopic list\n",
    "    - rostopic echo /agent/left_wheel_encoder_node/tick (right wheel)\n",
    "       - you should see no data\n",
    "    - open joypad / virtual joystick on novnc desktop\n",
    "    - press arrows\n",
    "    - you should see: images moving (don't crash on tree or you will have to restart!)\n",
    "    - on terminal, see wheel encoder data, e.g.\n",
    "    \n",
    "```    \n",
    "---\n",
    "header: \n",
    "  seq: 527\n",
    "  stamp: \n",
    "    secs: 0\n",
    "    nsecs:         0\n",
    "  frame_id: ''\n",
    "data: 82\n",
    "resolution: 135\n",
    "type: 1\n",
    "---\n",
    "```    \n",
    "\n",
    "How to read the wheel encoder data: \n",
    "\n",
    "* `seq`: is ...\n",
    "* `data`: is the cumulative count of ticks from the wheel so far\n",
    "* note that ticks increase or decrease depending on if you are going forward or backwards\n",
    "* `resolution`: is the total number of ticks per encoders\n",
    "* `type`: ?\n",
    "\n",
    "## ðŸš™ Read data from wheel encoders\n",
    "\n",
    "- Open a terminal on your computer\n",
    "- - `dts exercises build` (unless you did it already, but it won't break anything if you do it again)\n",
    "- Make sure your Duckiebot is on and connected to the networks\n",
    "    - You can test this by opening the Dashboard or `ping ROBOTNAME.local` from your computer terminal\n",
    "-  `dts exercises test -b ROBOTNAME`\n",
    "    - find localhost address novnc and paste in browser (e.g. localhost:8087)\n",
    "    - open RQT image view, select compressed image topic from the dropdown menu\n",
    "        - you should see what your robot sees\n",
    "    - open LX terminal inside novnc\n",
    "        - rostopic list\n",
    "        - rostopic echo /agent/left_wheel_encoder_node/tick (right wheel)\n",
    "        - you should see no data\n",
    "    - open joypad / virtual joystick on novnc desktop (or just move wheels by hand)\n",
    "    - press arrows\n",
    "    - you should see: robot moving and data streaming\n",
    "    - on terminal, see wheel encoder data, e.g.\n",
    "\n",
    "``` \n",
    "---\n",
    "header: \n",
    "  seq: 5594\n",
    "  stamp: \n",
    "    secs: 0\n",
    "    nsecs:         0\n",
    "  frame_id: ''\n",
    "data: 13\n",
    "resolution: 135\n",
    "type: 1\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the number of ticks from each wheel\n",
    "\n",
    "The wheel encoder message above provides several pieces of information. Let's extract the number of ticks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to get value of \"data\" from each wheel\n",
    "fn = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Evaluating rotation of each wheel\n",
    "\n",
    "Let's use the above to measure how much each wheel has rotated \n",
    "\n",
    "### Wheel encoder calibration factor\n",
    "\n",
    "- There are 135 ticks per revolution on these wheel encoders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_tot = 135 # total number of ticks per revolution\n",
    "alpha = 2 * np.pi / N_tot # wheel rotation per tick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call fn defined above:\n",
    "\n",
    "- At time t: ticks_l(t) = measure ticks from one wheel\n",
    "- At time t+1: ticks_l(t+1) = measure ticks from same wheel\n",
    "- delta_ticks_left = ticks_l(t+1) - ticks_l(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write function to get delta ticks\n",
    "\n",
    "delta_ticks_left = ... # delta ticks of left wheel in arbitrary dt\n",
    "delta_ticks_right = ... # delta ticks of right wheel in same dt\n",
    "\n",
    "rotation_wheel_left = alpha * delta_ticks_left # total rotation of left wheel in dt\n",
    "rotation_wheel_right = alpha * delta_ticks_right # total rotation of right wheel in dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluate distance travelled by each wheel\n",
    "\n",
    "Now let's calculate the distance travelled by each wheel. It depends on the wheel radii. \n",
    "\n",
    "Take a ruler and measure you wheel radii (let's assume they are the same):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 0.033 # insert value measured by ruler, in *meters* (Jacopo measures a diameter of 6.6cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance travelled by each wheel in one time step: \n",
    "\n",
    "d_left = R * delta_ticks_left \n",
    "d_right = R * delta_ticks_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate distance travelled by the origin of the robot frame, and the robot's rotation\n",
    "\n",
    "The travelled distance of point A (origin of the robot frame) is given by the average of the distances travelled by the wheels (given they symmetry assumption of the Duckiebot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_A = (d_left + d_right)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "### Step 10\n",
    "\n",
    "Write in the cell below the code to estimate the pose of the Duckiebot using data given by the wheel encoders.\n",
    "\n",
    "**DO NOT CHANGE THE NAME OF THE FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "export"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np # already imported above \n",
    "\n",
    "# DO NOT CHANGE THE NAME OF THIS FUNCTION\n",
    "def poseEstimation( R,\n",
    "                    L,\n",
    "                    x_prev,\n",
    "                    y_prev,\n",
    "                    theta_prev,\n",
    "                    delta_phi_left,\n",
    "                    delta_phi_right):\n",
    "    \"\"\"\n",
    "        Calculate the current Duckiebot pose using dead reckoning approach,\n",
    "        based on the kinematic model.\n",
    "\n",
    "        Returns:\n",
    "            x_curr, y_curr, theta_curr (:double: values)\n",
    "    \"\"\"\n",
    "    # x_curr = x_prev + R*(delta_phi_left+delta_phi_right)*np.cos(theta_prev)/2\n",
    "    # y_curr = y_prev + R*(delta_phi_left+delta_phi_right)*np.sin(theta_prev)/2\n",
    "    # theta_curr = theta_prev + R*(delta_phi_right-delta_phi_left)/(2*L)\n",
    "        \n",
    "    \n",
    "    w = [R, R/L, 1]\n",
    "    x = np.array(\n",
    "        [\n",
    "            [\n",
    "                (delta_phi_left+delta_phi_right)*np.cos(theta_prev)/2,\n",
    "                (delta_phi_left+delta_phi_right)*np.sin(theta_prev)/2,\n",
    "                0\n",
    "            ],\n",
    "            [\n",
    "                0,\n",
    "                0,\n",
    "                (delta_phi_right-delta_phi_left)/2],\n",
    "            [\n",
    "                x_prev,\n",
    "                y_prev,\n",
    "                theta_prev\n",
    "            ]\n",
    "        ])\n",
    "\n",
    "    x_curr, y_curr, theta_curr = np.array(w).dot(x)\n",
    "    \n",
    "    return x_curr, y_curr, theta_curr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Test\n",
    "\n",
    "Let's see if the function you wrote above passes the following test!\n",
    "\n",
    "Unit tests are useful to check if the piece of code you write does its job correctly.\n",
    "If the tests are good you will not see any output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert((poseEstimation(0.0318, 0.08, 0, 0, 0, -10*np.pi/180, 30*np.pi/180) == np.array([0.005550147021341967, 0.0, 0.1387536755335492])).all())\n",
    "assert((poseEstimation(0.0318, 0.08, 0, 0, 30*np.pi/180, 30*np.pi/180, 45*np.pi/180) == np.array([0.01802463118207754, 0.010406525665016188, 0.5756314039233797])).all())\n",
    "assert((poseEstimation(0.0318, 0.08, 0, 0, 0, 45*np.pi/180, 30*np.pi/180) == np.array([0.02081305133003238, 0.0, -0.05203262832508096])).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "### Build the Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "! cd .. && dts exercises build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "### Run the Activity in simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "! cd .. && dts exercises test --sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "After running the above command, open the following link http://localhost:8087 you will visualize the VNC. Then from the VNC open RVIZ, press the `Add` on the bottom left side of the window, after that go to the tab `topics` and select `/DUCKIEBOT_NAME/encoder_localization`. Finally open the joystick (on the Desktop) and move the robot. You will see that the pose arrow start moving according to the given commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "### Run the activity on the Duckiebot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "! cd .. && dts exercises test --duckiebot_name ![DB_NAME] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "After running the above command, open the following link http://localhost:8087 you will visualize the VNC. Then from the VNC open RVIZ, press the `Add` on the bottom left side of the window, after that go to the tab `topics` and select `/DUCKIEBOT_NAME/encoder_localization`. Finally open the joystick (on the Desktop) and move the robot. You will see that the pose arrow start moving according to the given commands."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
